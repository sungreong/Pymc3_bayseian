{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gaussian Processes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sungreong/Pymc3_bayseian/blob/master/Gaussian_Processes.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "lQE4_l_j-nHc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/pymc-devs/pymc3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CoEQ-FwWEO0z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reference https://docs.pymc.io/gp.html"
      ]
    },
    {
      "metadata": {
        "id": "rcrtOanISO8H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GP Basics \n",
        "\n",
        "파라미터와 변수를 모델에서 알지 못할 때  그것들은 상수나 고정된 벅테가 아니라 **함수**가 된다.  \n",
        "**Gaussian process(GP)** 는 연속전  함수들의 공간에 대한 정의역으로 가지는 사전 확률 분포로 사용 되어진다.  \n",
        "**f(x) 에 대한 GP prior**는 보통 $ f(x) \\sim gp(m(x) , k(x, x^{,} ) $ \n",
        "\n",
        "함수 값은 다둥 노말 분포로부터 뽑은 값이다. 평균 함수를 피라미라터 가진다. $m(x) and covariance function k(x, x^{''}) $  \n",
        "가우시안 프로세스들은 marginalization 때문에 함수에 대한 사전분포 선택이 편리하다.  \n",
        "보통 f(x) 에 대한 marginalization 분포는 **inference step** 동안 평가 되어진다.  \n",
        "조건부분포는 새로운 데이터 $x_* 에 대한 새로운 함수  f(x_*)$를 예측하는데 사용된다.\n",
        "\n",
        "![가우시안 분포](https://preview.ibb.co/dGPvyy/image.png)\n",
        "\n",
        "\n",
        "pymc3 는 완전한 베이지안 가우시안 프로세스 모델을 작업하기에 좋은 환경이다\n",
        "\n",
        "명백한 문법과 높은 구성도와 미리 정의된 covariance functions , mean functions and 몇몇 GP 시행하는 것들이 포함되어 있다.   \n",
        "GP는 크거나 위계가 있는 모델 안에서 다루어지고 홀로 이루어진 모델로써 되지 않는다."
      ]
    },
    {
      "metadata": {
        "id": "o8nvQC-z81Fx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Mean functions and Covariance functions  \n",
        "GPy , GPflow 패키지지가 mean function 과 covariance function 구조를 가진 문법 패키지 들이 있다.  \n",
        "처음 객체화 할때 mean 과 covariance 함수들은 파라미터화 한다.  그러나 인풋이 아직 주어진 것이 아니다.  \n",
        "covariance function은 반드시 추가적으로 인풋 메트릭스 안에서 큰 차원이 추가 되어야하고,   \n",
        "이러한 디자인의 이유는 covariance 함수가 다른 covariance 함수들과 결합이 된 구조를 이뤄야 하기 때문이다.\n",
        "\n",
        "\n",
        "예를 들어, 3 개의 예측 변수를 나타내는 3 열 행렬의 두 번째 및 세 번째 열에서 작동하는 지수화 된 2 차 공분산 함수를 생성하려면 다음을 수행합니다\n",
        "\n",
        "\n",
        "여기에서 ls 또는 lengthscale 매개 변수는 2 차원이므로 두 번째 및 세 번째 차원의 길이가 서로 다릅니다.  \n",
        "\n",
        "The reason we have to specify **input_dim**, the total number of columns of X,   \n",
        "and **active_dims**, which of those columns or dimensions the covariance function will act on, is because **cov_func hasn’t actually seen the input data yet**  \n",
        "**active_dims** argument is optional, and defaults to all columns of the matrix of inputs.\n",
        "\n",
        "\n",
        "## sum, product covariance functions\n",
        "```\n",
        "cov_func = pm.gp.cov.ExpQuad(...) + pm.gp.cov.ExpQuad(...)\n",
        "cov_func = pm.gp.cov.ExpQuad(...) * pm.gp.cov.Periodic(...)\n",
        "cov_func = eta**2 * pm.gp.cov.Matern32(...)\n",
        "```\n",
        "\n",
        "after the covariance function is defined ,  conv_func(), (mean_func()) 을 호출해서 계산한다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jxUxl89QSMhX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pymc3 as pm \n",
        "ls = [2, 5] # the lengthscales\n",
        "cov_func = pm.gp.cov.ExpQuad(input_dim=3, ls=ls, active_dims=[1, 2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ccAK9co5BbUF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GP Implementations\n",
        "\n",
        "PyMC3 includes several GP implementations, including marginal and latent variable models and also some fast approximations\n",
        "\n",
        "1. First, a GP is instantiated with a mean function and a covariance function.\n",
        "2. Then, GP objects can be added together, allowing for function characteristics to be carefully modeled and separated. \n",
        "3. Finally, **one of prior, marginal_likelihood or conditional methods** is called on the GP object to actually construct the PyMC3 random variable that represents the function prior.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "gp = pm.gp.Latent(mean_func, cov_func)\n",
        "```\n",
        "\n",
        "## Note\n",
        "The gp.Marginal class and similar don’t have a $ prior $ method.   \n",
        "Instead they have a $ marginal \\ likelihood $ method that is used similarly,   \n",
        "but has additional required arguments, such as the observed data, noise, or other, depending on the implementation.   \n",
        "See the notebooks for examples.$  The \\ conditional \\ method $ works similarly.\n",
        "\n",
        "\n",
        "```\n",
        "gp = pm.gp.Latent(mean_func, cov_func)\n",
        "Calling the prior method will create a PyMC3 random variable that represents the latent function f(x)=f:\n",
        "f = gp.prior(\"f\", X)\n",
        "```\n",
        "\n",
        "###  f is a random variable that can be used within a PyMC3 model like any other type of random variable.\n",
        "1. The first argument is the name of the random variable representing the function we are placing the prior over\n",
        "2.  The second argument is the inputs to the function that the prior is over, X. The inputs are usually known and present in the data, but they can also be PyMC3 random variables. \n",
        "3. If the inputs are a Theano tensor or a PyMC3 random variable, the shape needs to be given.\n",
        "\n",
        "\n",
        " inference is performed on the model.   \n",
        " The  $ conditional \\ method $ creates the conditional, or predictive, distribution over the latent function at arbitrary x∗ input points, $ f(x_∗). $To construct the conditional distribution we write:\n",
        "\n",
        "```\n",
        "f_star = gp.conditional(\"f_star\", X_star)\n",
        "```\n",
        "\n",
        "## Additive GPs\n",
        "\n",
        "```\n",
        "gp1 = pm.gp.Marginal(mean_func1, cov_func1)\n",
        "gp2 = pm.gp.Marginal(mean_func2, cov_func2)\n",
        "gp3 = gp1 + gp2\n",
        "```\n",
        "![대체 텍스트](https://preview.ibb.co/jgj1oy/gpgp.png/)\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "with pm.Model() as model:\n",
        "    gp1 = pm.gp.Marginal(mean_func1, cov_func1)\n",
        "    gp2 = pm.gp.Marginal(mean_func2, cov_func2)\n",
        "\n",
        "    # gp represents f1 + f2.\n",
        "    gp = gp1 + gp2\n",
        "\n",
        "    f = gp.marginal_likelihood(\"f\", X, y, noise)\n",
        "\n",
        "    trace = pm.sample(1000)\n",
        " ```\n",
        " To construct the conditional distribution of gp1 or gp2, we also need to include the additional arguments, X, y, and noise:\n",
        " ```\n",
        "  \n",
        " with model:\n",
        "    # conditional distributions of f1 and f2\n",
        "    f1_star = gp1.conditional(\"f1_star\", X_star,\n",
        "                              given={\"X\": X, \"y\": y, \"noise\": noise, \"gp\": gp})\n",
        "    f2_star = gp2.conditional(\"f2_star\", X_star,\n",
        "                              given={\"X\": X, \"y\": y, \"noise\": noise, \"gp\": gp})\n",
        "\n",
        "    # conditional of f1 + f2, `given` not required\n",
        "    f_star = gp.conditional(\"f_star\", X_star)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "This second block produces the conditional distributions.   \n",
        "Notice that extra arguments are required for conditionals of f1 and f2, but not f.  \n",
        "This is because those arguments are cached when .**marginal_likelihood** is called on **gp.**\n",
        "\n",
        "\n",
        "## Note\n",
        "\n",
        "When constructing conditionals, the additional arguments X, y, noise and gp must be provided as a dict called given!\n",
        "\n",
        "\n",
        "Since the marginal likelihoood method of **gp1 or gp2 weren’t called**, **their conditionals** need to be provided with **the required inputs.**   \n",
        "In the same fashion as the prior, f_star, f1_star and f2_star are random variables that can now be used like any other random variable in PyMC3.  \n",
        "Check the notebooks for detailed demonstrations of the usage of GP functionality in PyMC3.\n"
      ]
    },
    {
      "metadata": {
        "id": "36MjML4N-xQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0802f106-3ec7-4b94-b73e-d5aa998965aa"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-135363f8ff8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLatent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mean_func' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "VgYXRUZh-2q1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}